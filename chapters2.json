{
    "Chapter III": ": The Wrath of  \nExponentially -Large State \nSpaces \n\n2Outline\nProblem -solving agents\nProblem types\nProblem formulation\nExample problems\nBasic search algorithms\n\n3Overview\nRecall ourprevious discussion of  reflex agents . Such agents cannot operate well \nin environments for which the state to action mapping is too large to store or \nwould take too long to learn. \nProblem -solving agents use atomic representations (see",
    "Chapter 2": "), where \nstates of  the world are considered as wholes, with no internal structure visible to \nthe problem -solving agent . \nWe consider twogeneral classes of  search: (1) uninformed search algorithms for \nwhich the algorithm is provided no information about the problem other than its \ndefinition; (2) informed search , where the algorithm is given some guidance. \n4Overview\nIntelligent agents are supposed to maximize their performance measure ; \nachieving this is sometimes simplified if  the agent can adopt a goal and aim to \nsatisfy it.\nGoals help organize behavior by limiting objectives. We consider a goal to be a set \nof  world states –exactly those states in which the goal is satisfied. \nHere we consider environments thatareknown , observable ,discrete and \ndeterministic (i.e. each action has exactly one corresponding outcome). \nThe process oflooking forasequence ofactions thatreaches the goal is called \nsearch . A search algorithm takes a problem as input and returns a solution in \nthe form of  an action sequence. \n5Well-defined problems and solutions\nA problem can be defined formally by (5) components: \n(1)Theinitial state from which theagent starts.\n(2)Adescription ofpossible actions available totheagent: ACTIONS(s)\n(3) A description of  what each action does, i.e. the transition model , specified by \na function RESULT ( s,a)=a’.\nTogether, the initial state, actions and transition model implicitly defined the state \nspace of  the problem –the set of  all states reachable from the initial state by any \nsequence of  actions. \nThestate space forms adirected network orgraph inwhich thenodes arestates\nandtheedges between nodes areactions. Apath inthestate space isasequence\nofstates connected byasequence ofactions.\n\n6Well-defined problems and solutions\n(4)The goal test , which determines whether a given state is a goal state. \nFrequently the goal test is intuitive (e.g. check if  we arrived at the destination) –\nbut note that it is also sometimes specified by an abstract property (e.g. “check \nmate”).\n(5) A path cost function that assigns a numeric cost to each path. The problem -\nsolving agent chooses a cost function that reflects its own performance measure. \nCommonly (but notalways), thecostofapath isadditive interms ofthe\nindividual actions along apath. Denote the step cost to take action ‘a’ in state s, \narriving in s’ as: c(s,a,s’). \nA key element ofsuccessful problem formulation relates toabstraction –the\nprocess ofremoving (inessential) details from aproblem representation .\n7Problem -solving agents\n\n8Example: Romania\nOn holiday in Romania; currently in Arad.\nFlight leaves tomorrow from Bucharest\n\nFormulate goal :\nbe in Bucharest\n\nFormulate problem :\nstates : various cities\nactions : drive between cities\n\nFind solution :\nsequence of  cities, e.g., Arad, Sibiu, Fagaras , Bucharest\n9Example: Romania\n\n10Problem types\nDeterministic, fully observable single -state problem\nAgent knows exactly which state it will be in; solution is a sequence\n\nNon-observable sensorless problem (conformant problem)\nAgent may have no idea where it is; solution is a sequence\n\nNondeterministic and/or partially observable contingency \nproblem\npercepts provide newinformation about current state\noften interleave search, execution\n\nUnknown state space exploration problem\n11Example: vacuum world\nSingle -state, start in #5. \nSolution?\n\n\n12Example: vacuum world\nSingle -state, start in #5. \nSolution? [Right, Suck]\n\nSensorless , start in \n{1,2,3,4,5,6,7,8 }e.g., \nRight goes to { 2,4,6,8 } \nSolution?\n\n\n13Example: vacuum world\n Sensorless , start in \n{1,2,3,4,5,6,7,8 }e.g., \nRight goes to { 2,4,6,8 } \nSolution?\n[Right,Suck,Left,Suck ]\nContingency\nNondeterministic: Suck may \ndirty a clean carpet\nPartially observable: location, dirt at current location.\nPercept: [L, Clean], i.e., start in #5 or #7\nSolution?\n\n14Example: vacuum world\n Sensorless , start in \n{1,2,3,4,5,6,7,8 }e.g., \nRight goes to { 2,4,6,8 } \nSolution?\n[Right,Suck,Left,Suck ]\n\nContingency\nNondeterministic: Suck may \ndirty a clean carpet\nPartially observable: location, dirt at current location.\nPercept: [L, Clean], i.e., start in #5 or #7\nSolution? [Right, ifdirt then Suck]\n\n15Selecting a state space\nReal world is absurdly complex \nstate space must be abstracted for problem solving\n(Abstract) state = set of  real states\n(Abstract) action = complex combination of  real actions\ne.g., \"Arad Zerind \" represents a complex set of  possible routes, \ndetours, rest stops, etc. \nFor guaranteed realizability, anyreal state \"in Arad“ must get to \nsome real state \"in Zerind \"\n\n(Abstract) solution = \nset of  real paths that are solutions in the real world\nEach abstract action should be \"easier\" than the original \nproblem\n16Vacuum world state space graph\nStates: integer dirt and robot location.\nActions: Left, Right, Suck.\nGoal test: no dirt at all locations.\nPath cost: 1 per action.\n\n17Example: The 8 -puzzle\nStates: Locations of  tiles.  (Q: How large is state space?)\nActions: Move blank left, right, up, down.\nGoal test: s==goal state.    (given)\nPath cost: 1 per move.\n[Note: optimal solution of  n-Puzzle family is NP -hard]\n\n18Example: 8-queen s\nStates : Any arrangement of  0 to 8 queens on the \nboard.\nActions : Add a queen to any empty square.\nTransition Mode l: Returns the board with a queen added to the \nspecified square. \nGoal Test : 8 queens on the board, none attacking.\nQ:How many possible sequences? (~1.8x1014)\nRevision to problem : arrange queens with one per column, in the \nleftmost n columns, with no queen attacking another. \nActions: Add aqueen toanysquare in leftmost empty column (with \nno attacking) reduction to just 2,057 states !\n19Example: robotic assembly\nStates : Real -valued coordinates of  robot joint angles parts of  the \nobject to be assembled.\nActions : Continuous motions of  robot joints.\nGoal test : Complete assembly.\nPath cost : Time to execute.\nOther examples: TSP (NP -hard), robot navigation, protein folding \n(unsolved). \n\n20Searching for Solutions\nRecall that a solution is an actions sequence ; accordingly, search \nalgorithms work by considering various possible action sequences. \nThe possible action sequences starting at the initial state form a \nsearch tree with the initial state at the root; the branches are actions \nand the nodes correspond to state in the state space of  the problem. \nToconsider taking various actions, weexpand thecurrent state –\nthereby generating anewsetofstates.\nIn this way, we add branches from the parent node to children \nnodes . \n\n21Searching for Solutions\nAnode with nochildren iscalled aleaf;the set of  all leaf  nodes \navailable for expansion at any given point is called the frontier . \nThe process of  expanding nodes on the frontier continues until \neither a solution is found or there are no more states to expand. \nWe consider the general TREE -SEARCH algorithm next. \nAll search algorithms share this basic structure ; they vary primarily \naccording to how they choose which state to expand next –the so -\ncalled search strategy. \nIngeneral, aTREE -SEARCH considers all possible paths (including \ninfinite ones), whereas a GRAPH -SEARCH avoids consideration of  \nredundant paths . \n22Tree search algorithms\nBasic idea:\nOffline , simulated exploration of  state space by generating \nsuccessors of  already -explored states ( a.k.a.~ expanding states )\n\n23Tree search example\n\n24\nTree search example\n25\nTree search example\n26Implementation: general tree search\n\n27Searching for Solutions\nNaturally, if  we allow for redundant paths , then a formerly \ntractable problem can become intractable” “Algorithms that forget \ntheir history are doomed to repeat it.” \nTo avoid exploring redundant paths we can augment the TREE -\nSEARCH algorithm with a data structure called the explored set , \nwhich remembers every expanded node (we discard nodes in\nexplored setinstead ofadding them to the frontier). \n28Infrastructure for search algorithms\nSearch algorithms require a data structure to keep track of  the \nsearch tree that is being constructed. \nFoeeach node nof  the tree , we have a structure with (4) \ncomponents: \n(1)n.STATE :thestate inthestate space towhich thenode\ncorresponds.\n(2)n.PARENT : the node inthesearch treethatgenerated this\nnode.\n(3) n.ACTION : the action that was applied to the parent to \ngenerate the node. \n(4)n.PATH -COST : the cost, traditionally denoted g(n), of  the \npath from the initial state to the node, as indicated by the parent \npointers. \n29Implementation: states vs. nodes\nA state is a (representation of) a physical configuration.\nA node is a data structure constituting part of  a search tree includes \nstate, parent node , action , path cost g(x), depth.\nThe Expand function creates new nodes, filling in the various fields \nand using the Successor function of  the problem to create the \ncorresponding states .\n\n30Infrastructure for search algorithms\nNow that we have nodes ( quadata structures), we need to put them somewhere. \nWeuseaqueue , with operations: \nEMPTY?(queue): returns true only if  no elements\nPOP(queue): removes thefirstelement ofthequeue andreturns it.\nINSERT(element, queue): inserts an element and returns the resulting queue. \nRecall that queues are characterized by the order in which the store the inserted \nnodes:\nFIFO (first-in, first -out): pops the oldest element of  the queue.\nLIFO (last-in, first -out, i.e. a stack ) pops the newest element. \nPRIORITY QUEUE : pops element with highest “priority.”\n31Search strategies\nA search strategy is defined by picking the order of  node expansion\nStrategies are evaluated along the following dimensions:\ncompleteness : does it always find a solution when one exists?\ntime complexity : number of  nodes generated\nspace complexity : maximum number of  nodes in memory\noptimality : does it always find a least -cost solution ?\nTime and space complexity are measured in terms of  \nb:maximum branching factor of  the search tree\nd: depth of  the least -cost solution\nm: maximum depth of  the state space (may be ∞)\nThe size of  the state space graph (|V|+|E|)\n32Search strategies\nIn more detail:\nTime andspace complexity arealways considered with respect tosome\nmeasure oftheproblem difficult (e.g.|V| + |E|).\nInA.I., thestate space graph isoften represented implicitly by the initial state, \nactions and transition model (i.e. we don’t always store it explicitly).\nSearch algorithm complexity isfrequently expressed interms of:\nb: branching factor (maximum number of  successors of  any node)\nd:depth (of  the shallowest goal node)\nm: maximum length ofanypath inthestate space.\nTo assess the effectiveness of  a search algorithm, we can consider just the search \ncost, which typically depends on time complexity (and/or memory usage); total \ncost combines search cost and path cost of  the solution. \n33Uninformed search strategies\nUninformed search strategies use only the information available in \nthe problem definition.\nBreadth -first search\nUniform -cost search\nDepth -first search\nDepth -limited search\nIterative deepening search\n34Breadth -first search\nBFS is a simple strategy in which the root node is expanded first, \nthen all the successors of  the root node are expanded next, then \ntheir successors, etc. \nBFS isaninstance ofthegeneral graph -search algorithm inwhich\ntheshallowest unexpanded node is chosen for expansion . \nThis is achieved by using a FIFO queue for the frontier. \nAccordingly, newnodes gototheback ofthequeue, andold\nnodes, which areshallower than thenew nodes areexpanded\nfirst.\nNB: The goal test is applied to each node when it is generated .\n35Breadth -first search\nExpand shallowest unexpanded node\nImplementation :\nfrontier is a FIFO queue, i.e., new successors go at end\n\n36\nBreadth -first search\nExpand shallowest unexpanded node\nImplementation :\nfrontier is a FIFO queue, i.e., new successors go at end\n37\nBreadth -first search\nExpand shallowest unexpanded node\nImplementation :\nfringe is a FIFO queue, i.e., new successors go at end\n38\nBreadth -first search\nExpand shallowest unexpanded node\nImplementation :\nfringe is a FIFO queue, i.e., new successors go at end\n39Properties of  BFS\nComplete? Yes (if  bis finite )\nTime? 1+b+b2+b3+… + bd= O(bd)\nSpace? O(bd)(keeps every node in memory )\nOptimal? Yes (if  cost = 1 per step )\nSpace is the bigger problem (more than time )\n40Uniform -cost search\nExpand least -cost unexpanded node\nImplementation :\nfrontier = queue ordered by path cost\nEquivalent to breadth -first if  step costs all equal\nComplete? Yes, if  step cost ≥ ε\nTime? # of  nodes with g ≤cost of  optimal solution, O(bceiling (C*/ ε))\nwhere C*is the cost of  the optimal solution\nSpace? # of  nodes with g≤ cost of  optimal solution, O(bceiling (C*/ ε))\nOptimal? Yes –nodes expanded in increasing order of  g(n)\n41Depth -first search\nDFS always expands the deepest node in the current frontier of  the \nsearch tree. The search proceeds immediately tothedeepest level fo\nthesearch tree, where thenodes have nosuccessors.\nAs those nodes are expended, they are dropped from the frontier, so \nthen the search “backs up” to the next deepest node thatstillhas\nunexplored successors. \nDFS is an instance of  the general graph -search algorithm which uses \na LIFO queue. This means that the most recently generated node is \nchosen for expansion. \n42\nDepth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n43Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfringe = LIFO queue, i.e., put successors at front\n\n44\nDepth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n45\nDepth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n46\nDepth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n47Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n48Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n49Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n50Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n51Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n52Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n53Depth -first search\nExpand deepest unexpanded node\nImplementation :\nfrontier = LIFO queue, i.e., put successors at front\n\n54Properties of  depth -first search\nComplete? No: fails in infinite -depth spaces, spaces with \nloops\nModify to avoid repeated states along path\ncomplete in finite spaces\nTime? O(bm): terrible if  mis much larger than d\nbut if  solutions are dense, may be much faster than breadth -first\nSpace? O(bm), i.e., linear space !\nOptimal? No\n55Depth -limited search\nThe failure of  DFS in infinite state spaces can be alleviated by \nsuppling DFS with a pre -determined depth limit l, i.e., nodes at \ndepth lhave no successors. \n\n56Iterative deepening search\nIterative deepening search is a general strategy, often used in \ncombination with DFS tress search, that finds the best depth limit. \nItdoes thisbygradually increasing thelimit –first0,then 1,then\n2,andsoon–until agoalisfound; this will occur when the depth \nlimit reaches d, the depth of  the shallowest goal node. \nNote that iteratively deepening search may seem wasteful because \nstates are generated multiple times, but this, in fact, turns out not to \nbe too costly (the reason is that most of  the nodes are in the bottom \nlevel for a constant branching factor). \n57Iterative deepening search\nNumber of  nodes generated in a depth -limited search to depth d\nwith branching factor b: \nNDLS= b0+ b1+ b2+ … + bd-2+ bd-1+ bd\nNumber of  nodes generated in an iterative deepening search to \ndepth dwith branching factor b: \nNIDS= (d+1)b0+ d b^1+ (d-1)b^2+ … + 3bd-2+2bd-1+ 1bd\nFor b = 10 , d = 5 ,\nNDLS = 1 + 10 + 100 + 1,000 + 10,000 + 100,000 = 111,111\nNIDS= 6 + 50 + 400 + 3,000 + 20,000 + 100,000 = 123,456\nOverhead = (123,456 -111,111)/111,111 = 11%\n58Iterative deepening search\n\n59Iterative deepening search l =0\n\n60Iterative deepening search l =1\n\n61Iterative deepening search l =2\n\n62Iterative deepening search l =3\n\n63Properties of  iterative deepening search\nComplete? Yes\nTime? (d+1)b0+ d b1+ (d-1)b2+ … + bd= O(bd)\nSpace? O(bd)\nOptimal? Yes, if  step cost = 1\n64Bidirectional search\nThe main idea with bidirectional search is to run two simultaneous\nsearches –one forward from the initial state and the other backward \nfrom the goal –hope that the two searches meet in the middle. \nKey: bd/2+bd/2<< bd.\nReplace goal test with check toseewhether frontiers intersect.\nTime complexity (with BFS inboth directions): O( bd/2); space \ncomplexity: O( bd/2); space requirement is a serious weakness .\nAlso, itisnotalways asimple matter to“search backward ”–goal \nstate could beabstract.\n\n65Summary of  algorithms\n\n66Repeated states\nFailure to detect repeated states can turn a linear \nproblem into an exponential one!\n\n\n67Graph search\n\n68Summary\nBefore an agent can start searching for solutions, a goal must be \nidentified and a well -defined problem formulated. \nProblem formulation usually requires abstracting away real -world \ndetails to define a state space that can feasibly be explored\nAproblem consists of  (5) parts: initial state , actions , transition \nmodel , goal test function and path cost function. \nThe environment of  the problem is represented by the state space. \nA path through the state space from the initial state to a goal state is \na solution. \nTREE -SEARCH considers all possible paths; GRAPH -SEARCH \navoids consideration of  redundant paths. \n69Summary\nSearch algorithms arejudged onthebasis ofcompleteness ,optimality ,\ntime complexity and space complexity . Complexity depends on b, the \nbranching factor in the state space and d, the depth of  the shallowest \nsolution. \nUniformed search methods have access only the problem definition, \nincluding: \nBFS –expands the shallowest nodes first\nUniform -cost search –expands the node with the lowest path cost, g(n). \nDFS –expands thedeepest unexpanded node first (depth -limited search adds \na depth bound).\nIterative Deepening Search –calls DFS with increasing depth limits until a\ngoalisfound.\nBidirectional Search –can reduce time complexity butnotalways\napplicable."
}